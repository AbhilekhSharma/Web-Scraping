# -*- coding: utf-8 -*-
"""Web-Scraping for stack overlow

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14TWeUISxu60mrdZVNHLooTD6YBfB5oNO
"""

!pip install pandas

"""Developed a python script to scrape most voted questions from Stack Overflow using the requests library.
Coded the script to convert questions into CSV file and avoided repetition of questions using the pandas library.
Programmed it further to create a question bank for other languages.
"""

!pip install requests-html

import requests
from requests_html import HTML
import time
import pandas as pd

base_url='https://stackoverflow.com/questions/tagged/'
tag="python"
querry_filter="Votes"
url=f"{base_url}{tag}?tab={querry_filter}"
url

r=requests.get(url)
html_str=r.text

html=HTML(html=html_str)

question_summaries=html.find(".question-summary")
print(question_summaries)

question_summaries[0].text

columns=['votes','vote_title','num_ans','views','question','short_description','tags','date','user','user_details']

# curr_row=list(question_summeries[0].text.split("\n"))
# print(curr_row)

# row_data=dict(zip(columns,curr_row))
# row_data

key_names = ['question', 'votes', 'tags']
classes_needed = ['.question-hyperlink', '.vote', '.tags']
this_question_element = question_summaries[0]
this_question_element.find('.question-hyperlink', first=True).text
this_question_element.find('.vote', first=True).text.replace('\nvotes', '')
datas = []

def clean_scraped_data(text, keyname=None):
    if keyname == 'votes':
        return text.replace('\nvotes', '')
    return text

for q_el in question_summaries:
    question_data = {}
    for i, _class in enumerate(classes_needed):
        sub_el = q_el.find(_class, first=True)
        keyname = key_names[i]
        question_data[keyname] = clean_scraped_data(sub_el.text, keyname=keyname)
    datas.append(question_data)

datas[0]

def parse_tagged_page(html):
    question_summaries = html.find(".question-summary")
    key_names = ['question', 'votes', 'tags']
    classes_needed = ['.question-hyperlink', '.vote', '.tags']
    datas = []
    for q_el in question_summaries:
        question_data = {}
        for i, _class in enumerate(classes_needed):
            sub_el = q_el.find(_class, first=True)
            keyname = key_names[i]
            question_data[keyname] = clean_scraped_data(sub_el.text, keyname=keyname)
        datas.append(question_data)
    return datas

def extract_data_from_url(url):
    r = requests.get(url)
    if r.status_code not in range(200, 299):
        return []
    html_str = r.text
    html = HTML(html=html_str)
    datas = parse_tagged_page(html)
    return datas

def scrape_tag(tag = "python", query_filter = "Votes", max_pages=50, pagesize=25):
    base_url = 'https://stackoverflow.com/questions/tagged/'
    datas = []
    for p in range(max_pages):
        page_num = p + 1
        url = f"{base_url}{tag}?tab={query_filter}&page={page_num}&pagesize={pagesize}"
        datas += extract_data_from_url(url)
        time.sleep(1.2)
    return datas

datas = scrape_tag(tag='python')

len(datas)

df = pd.DataFrame(datas)
df.head()

df.shape

df.to_csv("python_stackoverflow.csv", index=False)